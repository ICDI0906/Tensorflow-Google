{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 加载数据\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = load_iris()\n",
    "train_data = data.data\n",
    "train_y = data.target\n",
    "data = np.hstack((train_data,train_y.reshape(-1,1)))\n",
    "np.random.shuffle(data)\n",
    "kflod = StratifiedKFold(n_splits = 10,shuffle = True, random_state = 42)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "dataset_size = data.shape[0]\n",
    "batch_size = 10\n",
    "w1 = tf.Variable(tf.random_normal([4, 100], stddev = 1, seed = 1))\n",
    "b1 = tf.Variable(tf.random_normal([100,1], stddev = 1, seed = 1))\n",
    "w2 = tf.Variable(tf.random_normal([100, 3], stddev = 1, seed = 1))\n",
    "# 指定大小为None的话，可以随意指定batch_size 的大小\n",
    "x = tf.placeholder(tf.float32, shape = (None, 4), name = \"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape = (None, 3), name =\"y-input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要执行的步骤\n",
    "a = tf.matmul(x, w1)\n",
    "y = tf.matmul(a, w2)\n",
    "pred = tf.nn.softmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义要优化的目标\n",
    "cross_entropy = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y))\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)\n",
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.one_hot(tf.argmax(pred,axis = 1), depth = 3),y_), tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 交叉熵损失函数\n",
    "$$h = -\\sum_{i=1}^{n}y_{i} * log(y_{i}^{'})$$ 其中$y_{i}$表示预测的第i个分量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95555556\n",
      "0.95555556\n",
      "0.9111111\n",
      "0.9111111\n",
      "1.0\n",
      "0.95555556\n",
      "1.0\n",
      "1.0\n",
      "0.95555556\n",
      "0.9111111\n"
     ]
    }
   ],
   "source": [
    "one_hot = OneHotEncoder()\n",
    "loss = []\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    for train_index, test_index in kflod.split(data[:,:-1],data[:,-1]):\n",
    "        train_data = data[train_index]\n",
    "        test_data = data[test_index]\n",
    "        Step = 100\n",
    "        for i in range(Step):\n",
    "            start = (i * batch_size) % dataset_size\n",
    "            end = min(start + batch_size, dataset_size)\n",
    "            label = tf.one_hot(train_data[start: end,-1],depth = 3)\n",
    "            label = sess.run(label)\n",
    "            sess.run(train_step, feed_dict = {x: train_data[start: end,:-1], y_ : label})\n",
    "#             if i % 1000 == 0:\n",
    "#                 total_cross_entropy = sess.run(cross_entropy, feed_dict = {x: data[start: end,:-1], y_: data[start:end,-1].reshape(-1,1)})\n",
    "#                 loss.append(total_cross_entropy)\n",
    "#                 print(\"after %d steps ,cross entropy on all data is %g\"%(i, total_cross_entropy))\n",
    "        test_label = tf.one_hot(test_data[:,-1],depth = 3)\n",
    "        test_label = sess.run(test_label)\n",
    "        print(sess.run(acc, feed_dict = {x : test_data[:,:-1],y_ : test_label}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "[[ 5.]\n",
      " [11.]]\n"
     ]
    }
   ],
   "source": [
    "# 复习一下tf中的简单的变量定义还有placeholder的定义\n",
    "import tensorflow as tf\n",
    "v = tf.Variable(tf.random_normal([2,3], stddev = 1,seed = 1))\n",
    "x = tf.placeholder(tf.float32, shape = (2,1), name = 'x_input')\n",
    "y = tf.placeholder(tf.float32, shape = (2,2), name = 'y_input')\n",
    "w = tf.matmul(y,x)\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(v))\n",
    "    print(sess.run(w, feed_dict = {x: [[1],[2]],y: [[1,2],[3,4]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.clip_by_value(x,min,max)\n",
    "clip_value = tf.placeholder(tf.int32, shape = [1], name = 'x')\n",
    "with tf.Session() as sess:\n",
    "    for i in range(20):\n",
    "        cliped = tf.clip_by_value(clip_value, 5,10)\n",
    "        print(sess.run(cliped ,feed_dict = {clip_value : [i]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "## tf.reduce_mean(tensor,axis = 0) 0 为列，而且算均值的时候是看数据类型的\n",
    "# v = tf.Variable(shape = (1,))\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.reduce_mean([0.0,1.0,0.0,1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79813886 0.59813887]\n"
     ]
    }
   ],
   "source": [
    "v1 = tf.constant([1,0])\n",
    "pred = tf.constant([[0.4,0.6],[0.6,0.4]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.nn.softmax_cross_entropy_with_logits(labels = v1, logits = pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# tf.reduce_sum() 应该是求所有的和\n",
    "with tf.Session() as sess:\n",
    "    v = tf.constant([1,2,3])\n",
    "    print(sess.run(tf.reduce_sum(v)))# output: [3 x 3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
